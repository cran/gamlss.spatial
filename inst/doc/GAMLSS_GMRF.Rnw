%\VignetteEngine{knitr::knitr} 
%\VignetteIndexEntry{The GMRF implementation in GAMLSS}
\documentclass[12]{article}

\usepackage{epsf}
\usepackage{Rd}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx} 
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{subfig}
\usepackage{makeidx}
\usepackage{multicol}
%\usepackage{upgreek}
\usepackage{enumerate} 
\usepackage{tikz}
%\usepackage{lipsum}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{natbib}
\usepackage{color}
\usepackage{rotating} 
%\usepackage{appendix} 
%\usepackage{ulem}
\usepackage{url}
\usepackage{inconsolata}
\usepackage{array}
\usepackage{marginnote}
\usepackage{subfig}
\usepackage{float}
\usepackage{parskip}
\usetikzlibrary{shapes,arrows}
\usepackage[stable]{footmisc}
\usepackage{dsfont}
\usepackage{longtable}
\usepackage{xspace}
\usepackage{multirow}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{natbib}
%\usepackage[latin1]{inputenc}
\usepackage{ctable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{color}

\renewcommand{\Re}{\mathds{R}}
\renewcommand{\R}{\textnormal{\sffamily\bfseries R}\xspace}

\newcommand{\rsection}[1]{\marginnote{{\small\R code  in \\ section \ref{#1}}}[-1in]}
\newcommand{\rpage}[1]{\marginnote{{\small\R code  on \\ page \pageref{#1}}}[-1in]}
\newcommand{\rfigure}[2][0.35]{\marginnote{{\small Figure \ref{#2}}}[#1 in]}
\newcommand{\NOTE}[1]{\marginnote{\textcolor{red}{#1}}}

\newcommand{\E}{\text{E}}
\newcommand{\V}{\text{Var}}
\newcommand{\SD}{\text{SD}}
%\newcommand{\GD}{\text{GD}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\theenumi}{\arabic{enumi}}
\renewcommand{\theenumii}{\alph{enumii}}
\renewcommand{\theenumiii}{\roman{enumiii}}
\renewcommand{\labelenumii}{(\theenumii)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\definecolor{darkmagenta}{rgb}{.5,0,.5}

\parindent=0in

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% gamlss notation: mu, sigma, nu, tau
\newcommand{\pone}{\mu}
\newcommand{\ptwo}{\sigma}
\newcommand{\pthree}{\nu}
\newcommand{\pfour}{\tau}
\newcommand{\oth}{\text{otherwise}}
\newcommand{\given}{\,|\,}
\newcommand{ \Rzeroone}{$(0,1)$}
\newcommand{\binary}{$\{0,1\}$}
\newcommand{\integers}{$\{0,1,2,\ldots\}$}
\newcommand{\binomintegers}{$\{0,1,\ldots,n\}$}
\newcommand{\greaterthantwo}{$(2,\infty)$}
\newcommand{\comma}{,}   %%% need this for csv files
\newcommand{\grb}[1]{\mbox{\boldmath $#1$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\Prob}{Prob}
%\DeclareMathOperator{\GDEV}{GDEV}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hyphenation{Like-lihood} \hyphenation{Jour-nal}
\hyphenation{Sta-sinopoulos Stasi-nopoulos Stasino-poulos Stasinopou-los}
\hyphenation{distri-bution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeindex

\begin{document}
%\SweaveOpts{concordance=TRUE}
%\SweaveOpts{concordance=TRUE}
\setlength{\marginparwidth}{2.5cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Put all global R commands and functions here
% <<child='Rscripts/scripts.Rnw'>>=
% @
%<<child='commands.Rnw'>>=
%@
% not need is put in scripts
%\SweaveInput{functions.Rnw}
%purl("/Users/MikisStasinopoulos/Dropbox/InflatedDistributions/Knitr/InflatedDistributioninR.Rnw")

\pagenumbering{arabic}
\title{The GMRF implementation in GAMLSS}
\pagenumbering{arabic}
\author{\bf{Fernanda De Bastiani}, \bf{Mikis Stasinopoulos} and \bf{Robert A. Rigby}}

\maketitle

\tableofcontents     % generates table of contents
%\listoffigures       % generates list of figures
%\listoftables  

%\chapter{The \texttt{gamlss.spatial} package}

\section{Introduction}


The package \code{gamlss.spatial} provides a set of functions to facilitate the fitting of spatial models within GAMLSS, \cite{RigbyStasinopoulos05}. At the moment it allows only Gaussian  Markov random fields (GMRF) terms, \cite{rue2005gaussian}, other spatial data facilities will be added in the future. Chapter 9 of  \cite{Stasinopoulosetal2017} provides more information of what other types of additive terms can be used within the \pkg{gamlss} packages. \cite{DBetal2016} describes the implementation of GMRF within GAMLSS and the material presented here is supplementary to this article.

Markov random fields (MRF) is a generic term to describe $k$ random variables whose joint distribution is specified using local conditional independence assumptions. This package uses spatial Gaussian Markov random field (GMRF) models. More specifically it uses intrinsic autoregressive models (IAR) (which are a limiting case of the conditional autoregressive models (CAR) of \cite{besag1974spacial}.  \cite{besag1995conditional} is a good reference for the definition of those models. The IAR models are ideal for modelling a response variable measured in geographical areas. When we model a response variable measured in areas we  expect  neighbouring areas to have a more similar response variable distribution than areas which are far apart. This is what a IAR term in the model for a response variable distribution parameter aims to achieve by bringing the fitted parameter values of neighbouring areas closer to each other. The fitting of an IAR model requires the specification of the precision matrix. The precision matrix can be constructed by using the geographical information of the areas.

The package provides several functions. The functions  \code{MRF()} and \code{MRFA()} are  appropriate for fitting a simple IAR model.  Those two functions  are called by the function \code{gmrf()} in order to fit an additive IAR term within the model for a response variable distribution parameter in the \code{gamlss()} function. 

Section \ref{The functions MRF() and MRFA()} provides information about the  \code{MRF()} and \code{MRFA()} functions and their arguments. Section \ref{Additional functions} describes additional functions for converting the way graphical information is stored. Section \ref{Example using} gives an example of using the \code{MRF()} and \code{MRFA()} functions. Section \ref{The GAMLSS additive function gmrf()} describes the GAMLSS additive function \code{gmrf()} and Section \ref{The rent99 data analysis} gives an example of its use. Conclusions are given in Section \ref{Conclusions}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The functions \texttt{MRF()} and \texttt{MRFA()}}
\label{The functions MRF() and MRFA()}

The model fitted by the two functions \texttt{MRF()} and \texttt{MRFA()} can be written as:
$${\bf y} = {\bf Z}{\grb \gamma} + {\grb \epsilon}  $$
where ${\bf Z}$ is an $n \times q$ incidence matrix ($Z_{ij}=1$ if observation $i$ belongs to area $j$ and $Z_{ij}=0$ otherwise),  ${\grb \gamma}$ is a $q \times 1$ vector of  random effects for the areas, and where $ {\grb \gamma} \sim N_q({\bf 0}, \sigma_b^2{\bf G}^{-1})$ for a specific scaled precision matrix ${\bf G}$ and ${\grb \epsilon}\sim N({\bf 0}, \sigma_e^2 {\bf W}^{-1})$ where ${\bf W}$ is a diagonal matrix of prior weights. If the number of observations equals the number of areas, then ${\bf Z}= {\bf I}$ the identity matrix. 
 %The form of the  matrix ${\bf G}$ is determining the local  IAR assumption that:
%$$\gamma_i|\gamma_{-i} \sim N(\displaystyle \sum_j \alpha_{ij} \gamma_j, k_i),$$ 
%where $\gamma_{-i}=(\gamma_1, \gamma_2, \ldots, \gamma{i-1}, \gamma{i+1}, \ldots, \gamma_q)$ and $\alpha_{ii}=0$, $\alpha_{ij}=-G_{ij}/G_{ii} (i \neq j)$ and $k_i = 1/(\lambda G_{ii})$ for $i=1,2, \ldots, q$, see \cite{banerjee2014hierarchical}[Chapter 3]. Given the above assumption it can be shown using  Brook's Lemma that the  joint distribution for ${\grb \gamma}$ is ${\grb \gamma} \sim N({\bf 0}, \sigma_b^2{\bf G}^{-1})$, (\cite{besag1974spacial}).

To estimate the random effect ${\grb \gamma}$'s one can use the (weighted) penalised least square solution 
$$\hat{\grb \gamma}= \left({\bf Z}{\bf W}{\bf Z}^\top +\lambda {\bf G}\right)^{-1} {\bf Z}^\top {\bf W}{\bf y}$$
where $\lambda=\sigma_e^2/\sigma_b^2$.

As described in \cite{DBetal2016}, assume that a response variable and explanatory variables are recorded at observations which belong spatially to one of a set of areas (or regions). Zero, one or more than one observation may be recorded in each region. To incorporate IAR models within the GAMLSS model, set ${\bf Z}$ to be an incidence matrix defining which observation belongs to which area, and let ${\grb \gamma}$ be the vector of $q$ spatial random effects and assume ${\grb \gamma} \sim N_q(0, \sigma_{b}^{2} {\bf G}^{-1})$, where ${\bf G}^{-1}$ is the (generalized) inverse of a $q\times q$ matrix, ${\bf G}$. In the following IAR model, based on \cite{BesagHigdon99}, the matrix ${\bf G}$ contains the information about the neighbours (adjacent regions), with elements given by $G_{mm}=n_m$ where $n_m$ is the total number of adjacent regions to region $m$ and $G_{mt}=-1$ if region $m$ and $t$ are adjacent, and zero otherwise, for $m=1,\ldots,q$ and $t=1,\ldots,q$. This model has the attractive property that conditional on $\sigma_{b}^{2}$ and $\gamma_t$ for all $t \neq m$, then $\gamma_m \sim
N(\sum{\gamma_t}n^{-1}_m, \sigma_{b}^{2} n_{m}^{-1} )$ where the summation is over all regions which are neighbours of region $m$. For a graphical interpretation of the nonzero pattern of the matrix ${\bf G}$ see \cite{DBetal2016}.

The functions \code{MRF()} and \code{MRFA()} differ in the way the estimates of $\sigma_e^2$ and $\sigma_b^2$ are calculated. Both functions use "local' maximum likelihood estimation as described in \cite{DBetal2016} and should give identical estimates.
The function \code{MRF()} maximizes numerically the log likelihood of the marginal normal likelihood (called the $Q$ function) in terms of parameters $\log\sigma^2_e$ and $\log\sigma^2_b$. Note that if the log-likelihood function is relatively flat  implementing an informative prior for $\log (\sigma_{e}^{2})$ can help convergence (using the argument \code{penalty}).
The function \code{MRFA()} fits the same IAR model as \code{MRF()} but it uses an alternating algorithm described in Chapter 3 of \cite{Stasinopoulosetal2017} and a special case of the one described in Section 2 of \cite{rigby2013automatic}. The estimates should be identical.  The function \code{MRF()} needs  starting values for the parameters $\sigma^2_e$ and $\sigma_b^2$, while \code{MRFA()} needs a starting value for $\lambda$. Note that while the function \code{MRF()} provides standard errors for the $\log \sigma^{2}_{e}$ ans $\log \sigma^{2}_{b}$,  the function \code{MRFA()} does not.


The arguments of the function \code{MRF()} are:
\begin{description}
  \item[\texttt{y}] response variable
  \item[\texttt{x}] a factor containing the areas
  \item[\texttt{precision}] the (scaled) precision matrix ${\bf G}$ if known
  \item[\texttt{neighbour}] an object containing the neighbour information for the areas
  \item[\texttt{polys}] the polygon geographical information if known
  \item[\texttt{area}] this argument is useful if we have more areas than levels of the factor \texttt{x}, (i.e. if there are some areas with no observations in the data set) . This specifies a factor containing all the areas.
  \item[\texttt{weights}] vector of prior weights (the diagonal of {\bf W})
  \item[\texttt{sig2e}] starting value for the error variance $\sigma_e^2$
  \item[\texttt{sig2bs}] starting value for the random effect variance  $\sigma_b^2$
  \item[\texttt{sig2e.fix}] whether $\sigma_{e}^{2}$ is fixed in the fitting, default equals \code{FALSE}
  \item[\texttt{sig2b.fix}] whether  $\sigma_{b}^{2}$ is fixed in the fitting, default equals \code{FALSE}
   \item[\texttt{penalty}] whether an extra quadratic penalty is required to help convergence in case the likelihood function is flat. This is equivalent of putting a normal prior distribution for $\log(\sigma^2_e)$ given by $\log(\sigma^2_e) \sim N(\mu_s, 1/\delta)$
   \item[\texttt{delta}] the precision of the prior i.e. $\delta$
   \item[\texttt{shift}] the mean of the prior i.e. $\mu_s$
\end{description}

The function \code{MRFA()} has extra arguments:

\begin{description}
  \item[\texttt{lambda}] for fixing the smoothing parameter for \code{MRFA()} function
  \item[\texttt{start}] starting value for the smoothing parameter $\lambda$ for \code{MRFA()} function
  \item[\texttt{df}] for fixing the degrees of freedom
\end{description}

Note that both \code{MRF()} and \code{MRFA()} create an \code{MRF} object in \R{}. There are several method to operate on a \code{MRF} object i) \code{fitted()}, ii) \code{coef()} iii)  \code{residuals()}  iv) \code{AIC()}  v) \code{deviance()} vi)  \code{plot()} vii) \code{print()} viii) \code{summary()}  ix) \code{logLik()} x) \code{predict()}.

\subsection{Additional functions}
\label{Additional functions}

First we explain 3 different ways in which the graphical information about the areas (or regions) can be stored:

\begin{description}
  \item[i)] a neighbour object is a {\tt R} list comprising each region label followed by its neighbouring region labels.  
  
  \item[ii)] a polygon object is a \texttt{R} list comprising the region label followed by coordinates of points in two columns in matrix form 
defining the boundary for each area.   
  
  \item[iii)] a (scaled precision) matrix {\bf G} is defined in Section \ref{The functions MRF() and MRFA()} for the specific IAR model fitted by the \textbf{gamlss.spatial} package which determines the prior distribution ${\grb \gamma} \sim N_q({\bf 0 }, \sigma_{b}^{2} {\bf G}^{-1})$ where ${\bf G}^{-1}$ is a generalized inverse of ${\bf G}$.
\end{description}

There are several additional supporting functions in the package:
\begin{description}
  \item[\texttt{nb2nb()}] transforms an object with neighbour information in a shapefile format (geospatial vector data format for geographic information system, written in \R{} as a \code{S4} object) to the neighbour required form for functions \code{MRF()} and \code{MRFA()}. The single argument takes a  \code{S4} neighbour object.  
  
  \item[\texttt{polys2nb()}] creates the neighbour object from the geographical polygons. The single argument takes a polygon object.   
  
  \item[\texttt{nb2prec()}] creates the matrix ${\bf G}$ from the neighbour information.There are three arguments here:
  
\begin{description}
  \item[\texttt{neighbour}] is a neighbour object.
  \item[\texttt{x}] is the area factor. This factor can have  less levels than the number of areas defined in the neighbour object.  In such cases the third argument \code{area} has to be specified.
  \item[\texttt{area}] all possible areas involved, with the number of areas is equal to the number of neighbours in the \textbf{\texttt{neighbour}} object of the first argument.
\end{description}
  
  \item[\texttt{polys2polys()}] transforms polygons in shapefile format (S4 object) to the polygons required form for the \code{MRF()} and \code{MRFA()}.
  \item[\texttt{draw.polys()}] Plots the fitted values a fitted \code{MRF} object. This function has arguments:
  \begin{description}
  \item[\code{polys}] An object containing the polygon information for the area.
  \item[\code{object}] This can be either a fitted \code{MRF} object or a vector  of values to plot. Note that in later case the vector should also  have names corresponding to the names of the \code{polys} (see the example below for how this can be achieved.).
  \item[\code{scheme}] The scheme of colours to use, it can be "heat", "rainbow", "terrain", "topo", "cm" or any colour.
  \item[\code{swapcolor}] To reverse the colours, it just works for "heat", "rainbow", "terrain", "topo", "cm" options.
  \item[\code{n.col}] A range for different colours.
\end{description}

  
\end{description}


\subsection{Example using  \texttt{MRF()} and \texttt{MRFA()} }
\label{Example using}



\bigskip
\begin{mdframed}[hidealllines=true,backgroundcolor=gray!20]
\begin{description}
  \item[\R{}  data file:] \code{columb} in package \pkg{mgcv} of dimensions $ 49 \times 8$
   \item[{\bf var}]
   \begin{description}
      \item[\texttt{area}]: land area of district 
    \item[\texttt{home.value}]: housing value in 1000USD
    \item[\texttt{income}]: household income in 1000USD.
    \item[\texttt{crime}]: residential burglaries and auto thefts per 1000 households (the response variable)
    \item[\texttt{open.space}]: measure of open space in district 
   \item[\texttt{district}]: code identifying district, and matching \code{names(columb.polys)}
    \item[\texttt{x,y}] middle point area coordinates
  \end{description}
  \item[purpose:] to demonstrate spatial functions in GAMLSS
\end{description}
\label{TheColumbData}
\end{mdframed}   

\textbf{Note}: in the above data set the variable \texttt{district} contains the names of the districts or regions or areas (and should not be confused with the variable area which is quantitative).

First we bring the data frame \code{columb} and the polygons file  \code{columb.polys} from the \pkg{mgcv} package. We also print the  polygon information for the first district of the data called district \code{"0"}.
<<message=FALSE>>=
library(gamlss.spatial) 
library(mgcv)
# bring the data
data(columb)
names(columb)
# getting the polygons file 
data(columb.polys)
head(columb.polys,1)
@

Above are the first district name \code{"0"} and the (horizontal and vertical) coordinates of the polygon defining the district.
We now use the function \code{polys2nb()} to translate the information from polygons to neighbours:
<<>>=
# getting the neighbours object from the polygons object
vizinhos <- polys2nb(columb.polys)
vizinhos[[1]]["0"]
@
For example the district \code{"0"} has as neighbours districts \code{"2"} and \code{"3'}. 

The function \code{nb2prec()} is used to get the (scaled precision) matrix ${\bf G}$ from the neighbour information. The created (scaled precision) matrix \code{precisionC} is an $49 \times 49$ matrix, but here we plot only its first  10 rows and 20 columns.
<<>>=
# getting the precision matrix from the neighbours object
precisionC <- nb2prec(vizinhos,x=columb$district)
precisionC[1:10, 1:20]
@
The first row indicates that region \code{"0"} has 2 neighbours regions \code{"1"} and \code{"2"}.

Now we will fit the IAR model using the two different functions  \texttt{MRF()} and \texttt{MRFA()}, but  also using  different geographical information i) polygons ii) neighbours and iii) (scaled precision) matrix ${\bf G}$. The \R{} function \code{system.time()} checks the speed of the procedures. The model which used the (scaled precision) matrix ${\bf G}$ should  be fastest, since all functions require  matrix ${\bf G}$ to be obtained for fitting.
<<>>=
# fit using the  polygone information
# MRFA alternaing 
system.time(m11<-MRFA(columb$crime, columb$district, polys=columb.polys))
# MRF Q-function
system.time(m21<-MRF(columb$crime, columb$district, polys=columb.polys))
# fit using the neighbour information
# MRFA alternaing
system.time(m12<-MRFA(columb$crime, columb$district,  neighbour=vizinhos))
# MRF Q-function
system.time(m22<-MRF(columb$crime, columb$district, neighbour=vizinhos))
# fit using the percision matrix
# MRFA alternaing
system.time(m13<-MRFA(columb$crime, columb$district, precision=precisionC))
# MRF Q-function
system.time(m23<-MRF(columb$crime, columb$district, precision=precisionC))
AIC(m11, m21, m12, m22, m13, m23, k=0)
@
All fitted models are identical, but note below the different information provided by object \code{MRF} when it is fitted using the function \code{MRF()} and when fitted  using \code{MRFA()}. The  algorithm used in  \code{MRFA()}, while generally  faster to converge, does not provides standard errors for the parameter estimates. The function \code{MRF()} also provides in addition the marginal deviance of the fit. 
<<>>=
summary(m11)
summary(m21)
@

<<eval=FALSE, echo=FALSE>>=
plot(m11)
wp(m11)
# both look terrible
# model for sigma?
@

Next we plot both the observed and the fitted response variable values in maps by using the function  \code{draw.polys()}. Note that the first argument of the function is the polygon information, while the second is either a vector (to plot the observed response variable value) or a fitted \code{MRF} model (to plot fitted response variable values). In the former case the vector should  contain the observed response variable values together with their district labels stored as \code{names}.  In commands  below we create the vector \code{cr} for the row crime figures and then we assign the names of the districts as names for \code{cr}.  [Note that if there were more than one observation in the same district, the mean \texttt{cr} for each district has to be computed (with names as the district labels) and replace \texttt{cr} with the computed mean \texttt{cr}.]
\rfigure{fig:ColumbData}
\label{r:ColumbData}
<<ColumbData, fig.show='hide', fig.asp=1>>=
cr <- columb$crime
names(cr) <- as.character(columb$district)
draw.polys(columb.polys, cr,   scheme="topo",swapcolors=TRUE)
title("(a) crime")
draw.polys(columb.polys, m11, scheme="topo",swapcolors=TRUE)
title("(b) smooth values")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{ColumbData-1}
\includegraphics[width=.49\textwidth]{ColumbData-2}
\rpage{r:ColumbData}
\caption{Showing (a) the actual crime figures and (b) the fitted values from the IAR model.}
\label{fig:ColumbData}
\end{figure}
Figure  \ref{fig:ColumbData}(a) shows that the range of the observed crime values is from 0 to 70, while from Figure \ref{fig:ColumbData}(b)  the range for the fitted (mean) crime values is between 10 and 60. The `shrinking' effect, where fitted (mean) values for different areas shrink towards their neighbours, is a typical behaviour in the IAR model. 


It would be of interest to see what will happen if data from one of the areas defined in the polygons is missing.  In this case  we will have less areas in the data than the number of polygons defined in the polygon file. We  will remove district \code{"4"} from the \code{columb} data set (but also level  \code{"4"}  for the factor \code{district}). In order to fit the model to the reduced data set we will need to define a factor which has as many levels as the number of areas in the polygon information file.  Our original \code{columb\$district} has this information and it will be used below, but in general we can get this information from the polygon file, i.e. \code{as.factor(names(columb.polys))}.  
<<>>=
# the dimension of the original data
dim(columb)
# removing one area (district ''4'') from  the data 
columb2 <- columb[-5,]
# drop unused level from a factor
columb2$district <-droplevels(columb2$district)
dim(columb2)
nlevels(columb2$district)
# fitting the reduced data 
# using  polys
r1<-MRF(columb2$crime, columb2$district, polys=columb.polys, 
        area=columb$district)
# using neighbours 
r2<-MRF(columb2$crime, columb2$district,  neighbour=vizinhos, 
        area=columb$district)
# using the old precision
r3<-MRF(columb2$crime, columb2$district, precision=precisionC,
        area=columb$district)
# creating new precision matrix
precisionC2 <- nb2prec(vizinhos, x=columb2$district, 
                       area=columb$district)
dim(precisionC2)
# fitting  using the new 49 x 49 precision
r4<-MRF(columb2$crime, columb2$district, precision=precisionC2,
         area=columb$district)
# checking the results
AIC(r1,r2,r3,r4, k=0)
@
All fitted models produce identical results. Note that one consequence of having less areas (i.e. districts in the above example) in the data than the actual  areas  in the polygons is that the $\grb \gamma$ has length equal to the areas of the polygons while the fitted values has less district values. For instance in our example we have 49 areas defined by \code{area='columb\$district'},  but in the data only 48 areas and with no repetition in areas. Therefore the estimated  $\hat{\grb \gamma}$ is of length 49, while the fitted values of the model are of length 48. Next using the function \code{plot.polys()} we plot the fitted (mean crime) values of model \code{r1} and the estimated   $\hat{\grb \gamma}$ from the same model.
\rfigure{fig:ColumbDataMis}
\label{r:ColumbDataMis}
<<ColumbDataMis, fig.show='hide', fig.asp=1>>=
draw.polys(columb.polys, fitted(r1), scheme="heat", swapcolors=TRUE )
title("(a)")
draw.polys(columb.polys, r1, scheme="heat",swapcolors=TRUE  )
title("(b)")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{ColumbDataMis-1}
\includegraphics[width=.49\textwidth]{ColumbDataMis-2}
\rpage{r:ColumbDataMis}
\caption{Showing (a) the fitted values of model \texttt{r1} and (b) the fitted  $\hat{\grb \gamma}$ from the same model.}
\label{fig:ColumbDataMis}
\end{figure}
Note the white region in Figure \ref{fig:ColumbDataMis}(a) indicating the missing fitted value for area \texttt{"4"}. The colour of the same area in Figure \ref{fig:ColumbDataMis}(b) is filled with a colour (similar to its neighbours) representing the estimated $\hat{\gamma}$ for area \texttt{"4"}.



\section{The GAMLSS additive function \texttt{gmrf()}}
\label{The GAMLSS additive function gmrf()}

The function which can be used within GAMLSS to fit an IAR model is \code{gmrf()}.
It has the following arguments:
\begin{description}
  \item[x] a factor containing the areas
  \item[precision] the (scaled) precision matrix ${\bf G}$ if set (the quickest way to fit the model),
  \item[polys] the polygon information if set, 
  \item[area] this argument is here to allow more areas than the levels of the factor \code{x}, as was described in Section \ref{The functions MRF() and MRFA()},
  \item[start] starting value for the smoothing parameter $\lambda$, only for \code{method="A"}
  \item[df] degrees of freedom for fitting if required, only for \code{method="A"}
  \item[method] \code{"Q"} for Q-function using \code{MRF()}, or \code{"A"} for alternating method using \code{MRFA()},
  \item[adj.weight]  a value to adjust the iterative weight if necessary (to achieve convergence of the algorithm).
\end{description}
[Note that some of the arguments of the functions \texttt{MRF()} and \texttt{MRFA()} can be used here (according to the method selected).]

First we fit model \code{g1}, the IAR model fitted using \code{gamlss()}, and we compare the results  with the model  \code{m21} fitted by \code{MRF()}. Notice that in the output below the fitted values for the $\mu$ parameter are identical, and so are the estimates $(18.47)$ for the parameter $\sigma_b$.  The estimates for the parameter $\sigma_e$ are different since the estimate $(6.77)$ from the \code{gamlss()} model [see \cite{RigbyStasinopoulos05} and \cite{Nelder2005}] is a maximum likelihood a posteriori (MAP) or penalized likelihood estimator, while the estimate (9.57) from \code{MRF()} is a REML estimator. Note that the \code{gamlss()} MAP estimator of $\sigma_e$ can be substantially negatively biased [i.e. underestimates $\sigma_e$ when, as here, the total effective degrees of freedom used in the model for $\mu$ ($23.47$, including the spatial smoother) is high relative to the sample size ($49$)]. This causes the deviances to be different in the two fitted models. Note that \code{gamlss()} uses a normal distribution for the response variable \code{crime} by default. 
<<warning=FALSE>>=
# fit the model
g1 <- gamlss(crime~gmrf(district,precision=precisionC), data=columb)
# comparing the fitted values
head(cbind(fitted(m21),fitted(g1)))
tail(cbind(fitted(m21),fitted(g1)))
#  the log-sigma coefficients
coef(m21)
coef(getSmo(g1))
# get sigma_b
m21$sigb
getSmo(g1)$sigb
# get sigma_e
m21$sige
fitted(g1,"sigma")[1]
# comparing the deviances
deviance(g1)
deviance(m21)
# get degrees of freedom for mu
g1$mu.df
@

The nice thing about GAMLSS is its flexibility and the fact  that you can check different models. 
Up to now we have used only the geographical information to model the crime figures. From Section \ref{Example using}, the dataset \code{columb} contains also other information like the available income, \code{income}, the value of homes in the area, \code{home.value}, the  open space  of the area, \code{open.space}, the size of the area, \code{area} and the coordinates of the middle points of the area. The latest two variables  can be used to fit a geostatistics type of model. Here we will use it to fit a two dimensional smooth surface to the crime figures. To fit the model we are using the function \code{ga()} which is an interface to the function \code{gam()} of Simon Wood's package \pkg{mgcv}
<<message=FALSE>>=
library(gamlss.add)
g2 <- gamlss(crime~ga(~s(x,y)), data=columb)
AIC(g1,g2)
@


\rfigure{fig:ColumbDataTwo}
\label{r:ColumbDataTwo}
<<ColumbDataTwo, fig.show='hide', fig.asp=1>>=
names(g1$mu.fv) <- names(g2$mu.fv) <- as.character(columb$district)
draw.polys(columb.polys, fitted(g2), scheme="terrain",swapcolors=TRUE  )
title("(a) 2-d smoothing")
draw.polys(columb.polys, fitted(g1), scheme="terrain", swapcolors=TRUE )
title("(b) IAR")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{ColumbDataTwo-1}
\includegraphics[width=.49\textwidth]{ColumbDataTwo-2}
\rpage{r:ColumbDataTwo}
\caption{Showing (a) the fitted values of the 2-dimensional smoothing model \texttt{g2} and (b) the fitted IAR model \texttt{g1}.}
\label{fig:ColumbDataTwo}
\end{figure}
<<eval=FALSE, echo=FALSE>>=
plot(fitted(g1)~fitted(g2))
@
One can combine the geographical information with the other available variables to built a suitable model for modelling the crime figures. Unfortunately  the number of observations in the data, $49$, is very small to do justice to such an analysis. Next we will build suitable models using explanatory variables but no-geographical information and then we will compare those models with the ones using only geographical information.

We start by selecting a suitable model using only linear terms. We are using the model selection function \code{stepGAIC()}. We first transform the \code{open.space} variable by taking its log.  

<<message=FALSE>>=
columb <- transform(columb, logos=log(open.space+1))
e0 <- gamlss(crime~1, data=columb)
# linear
e1 <- stepGAIC(e0, scope=list(lower=~1, upper=~area+income+home.value+logos))
formula(e1)
@
Linear terms for  \code{income} and \code{home.value} were selected. Figure \ref{fig:ColumbDataLinear} shows a visual representation of the model and how  they effect  the mean, $\mu$, of the response.

\rfigure{fig:ColumbDataLinear}
\label{r:ColumbDataLinear}
<<ColumbDataLinear, fig.show='hide', fig.asp=1>>=
term.plot(e1)
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.39\textwidth]{ColumbDataLinear-1}
\includegraphics[width=.39\textwidth]{ColumbDataLinear-2}
\rpage{r:ColumbDataLinear}
\caption{Showing term plots for the linear model \texttt{e1}.}
\label{fig:ColumbDataLinear}
\end{figure}
Note that by fitting the linear terms in \code{income} and \code{home.value} the geographical GMRF terms becomes redundant. As a result of this if you try to fit the following   model it will fail.
<<eval=FALSE>>=
ge1<- gamlss(crime~income+home.value+gmrf(district,precision=precisionC), 
             data=columb)
@
We are trying now to select a model using smooth additive terms. We are using P-splines and the function \code{pb()} as a smoother.  
<<message=FALSE, warning=FALSE, cache=TRUE>>=
e2 <- stepGAIC(e0, scope=list(lower=~1, upper=~pb(area)+pb(income)+
                      pb(home.value)+pb(logos)))
formula(e2)
@
Additive smoothing terms for\code{income}, \code{home.value} and \code{area} were selected this time. Figure \ref{fig:ColumbDataLinear} shows their effect on the mean, $\mu$, of the response variable \code{crime}. 
\rfigure{fig:ColumbDataAdditive}
\label{r:ColumbDataAdditive}
<<ColumbDataAdditive, fig.show='hide', fig.asp=1>>=
term.plot(e2)
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.29\textwidth]{ColumbDataAdditive-1}
\includegraphics[width=.29\textwidth]{ColumbDataAdditive-2}
\includegraphics[width=.29\textwidth]{ColumbDataAdditive-3}
\rpage{r:ColumbDataAdditive}
\caption{Showing term plots for additive model \texttt{e2}.}
\label{fig:ColumbDataAdditive}
\end{figure}
The GAMLSS framework allows the fitting of a neural network model for one or more of the distribution parameters of the model. This is done by the interface function \code{nn()} which calls the \code{nnet()} function of Brian Ripley's package \pkg{nnet}.  
We fit a neural network model for the mean of the response (i.e. parameter $\mu$).
\rfigure{fig:ColumbDataNeural}
\label{r:ColumbDataNeural}
<<ColumbDataNeural, fig.show='hide', fig.asp=1, warning=FALSE>>=
e3 <- gamlss(crime~nn(~income+home.value+logos+area, decay=0.1), data=columb)
term.plot(e3)
@
[Note in the above neural network fitting it may be better to rescale the explanatory variables to interval $[0,1]$, as recommended by \cite{Ripley96}[page 157].] 
\begin{figure}[!htbp]
\centering
\includegraphics[width=.59\textwidth]{ColumbDataNeural-1}
\rpage{r:ColumbDataNeural}
\caption{Showing a graphical interpretation of the  neural network model \texttt{e3}.}
\label{fig:ColumbDataNeural}
\end{figure}
While the neural network model can take into account interactions between the explanatory variables, unfortunately it is very difficult to interpret and usually over-fits the data. Figure \ref{fig:ColumbDataNeural} shows how the explanatory variables are  connected with three hidden variables (\code{H1, H2, H3}), where the thickness of the lines reflects how large the coefficients are. 

Finally we fit a decision tree model to the parameter $\mu$ of the model. 
\rfigure{fig:ColumbDataTree}
\label{r:ColumbDataTree}
<<ColumbDataTree, fig.show='hide', fig.asp=1, warning=FALSE>>=
e4 <- gamlss(crime~tr(~income+home.value+logos+area), data=columb)
term.plot(e4)
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.59\textwidth]{ColumbDataTree-1}
\rpage{r:ColumbDataTree}
\caption{Showing a term plot for the mean $\mu$ of the decision tree model \texttt{e4}.}
\label{fig:ColumbDataTree}
\end{figure}
Decision trees are easy to interpret as Figure \ref{fig:ColumbDataTree} shows, where the parameter $\mu$ is a function of \code{income},  \code{area} and \code{home.value}. In each split of the decision tree (e.g. \texttt{income>=11.76}) the left branch is YES (i.e. \texttt{income>=11.76}) and the right branch is NO (i.e. \texttt{income<11.76}).

We can compare the different models fitted here using AIC and SBC/BIC. 
<<>>=
AIC(g1,g2, e1, e2, e3, e4)
AIC(g1,g2, e1, e2, e3, e4, k=log(49))
@
The decision tree and neural network models using explanatory variables, i.e. models \code{e4} and \code{e3}, respectively, do better that the models using only geographical information, \code{g1} and \code{g2}, in this case.
Of course in a larger data set both may be needed as we show in the next section where we analyse the Munich rent data.

We finish our analysis by showing in Figure \ref{fig:ColumbDataFour} the fitted values for each of our four models on a map.

\rfigure{fig:ColumbDataFour}
\label{r:ColumbDataFour}
<<ColumbDataFour, fig.show='hide', fig.asp=1>>=
names(e4$mu.fv) <- names(e3$mu.fv) <- names(e2$mu.fv) <-
  as.character(columb$district)
draw.polys(columb.polys, fitted(g1), scheme="terrain", swapcolors=TRUE )
title("(a) IAR")
draw.polys(columb.polys, fitted(e2), scheme="terrain",swapcolors=TRUE  )
title("(b) Additive Smooth")
draw.polys(columb.polys, fitted(e3), scheme="terrain",swapcolors=TRUE  )
title("(c) neural network")
draw.polys(columb.polys, fitted(e2), scheme="terrain",swapcolors=TRUE  )
title("(d) decision tree")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.39\textwidth]{ColumbDataFour-1}
\includegraphics[width=.39\textwidth]{ColumbDataFour-2}\\
\includegraphics[width=.39\textwidth]{ColumbDataFour-3}
\includegraphics[width=.39\textwidth]{ColumbDataFour-4}
\rpage{r:ColumbDataFour}
\caption{Showing the fitted values for $\mu$ in four of our fitted models (a) the IAR/GMRF model \texttt{g2} and (b) the additive smoothing terms model \texttt{e2},
(c) neural network model \texttt{e3} and (d) decision tree model \texttt{e4}.}
\label{fig:ColumbDataFour}
\end{figure}

<<eval=FALSE, echo=FALSE>>=
# additive 
e4 <- gamlss(crime~pb(income)+pb(home.value)+pb(log(open.space+1)), data=columb)
# nn surface

k4 <- gamlss(crime~pbz(income)+pbz(home.value)+pbz(log(open.space+1))+pbz(area), data=columb)
k6 <- gamlss(crime~nn(~income+home.value+open.space+area, decay=0.1), data=columb)
AIC(g1,k2, k3, k4)
AIC(g1,k2, k3, k4, k=log(49))

# MRF fit using the  polygone information
#tem.time(m1<-MRFA(columb$crime, columb$district, polys=columb.polys))

# library(gamlss.add)
# k3 <- gamlss(crime~ga(~s(x,y)), data=columb)
# fv <- fitted(k3)
# names(fv) <- names(columb.polys)
# draw.polys(columb.polys, fv)
# k4 <- gamlss(crime~ga(~s(x,y)), data=columb, family=)
# plot(k4)
# fv <- fitted(k3)
# names(fv) <- names(columb.polys)
# draw.polys(columb.polys, fv)
# 
# k1 <- gamlss(crime~gmrf(district,precision=precisionC), data=columb, family=GU, bf.cyc=1, n.cyc=5, glm.t)
# #plot(k0)
# #draw.polys(columb.polys,fitted(k0), scheme="topo",swapcolors=TRUE)
# #draw.polys(columb.polys,resid(k0))
# 
# k1 <- gamlss(crime~income+home.value+open.space+gmrf(district, precision=precisionC, method="A"), data=columb)
# #k1 <- gamlss(crime~income+home.value+open.space+gmrf(district, precision=precisionC, method="Q"), data=columb)
# summary(k1)
# draw.polys(columb.polys,getSmo(k1))
@


\section{The \texttt{rent99} data analysis}
\label{The rent99 data analysis}
%\section{Methods diagnostics for fitted objects}

\subsection{The 1999s Munich rent data}
\label{The 1999's Munich rent data}

The \code{rent} data come from a survey  conducted in 1999,  a random sample of accommodation with new tenancy agreements or increases of rents.  The data  are in the package \pkg{gamlss.data} (which is automatically loaded when  \pkg{gamlss}  is loaded). There are 3081 observations on nine variables.
 %Accommodation subject to price control rents, one family houses and special houses, such as penthouses, were excluded because they are rather different from the rest and are considered a separate market.
The data were analyzed by \cite{DBetal2016} but here we  reproduce the results to demonstrate how the package  \pkg{gamlss.spatial} is working in  \R{}.    %\cite{StasinopoulosetalModelling}  

\bigskip
\begin{mdframed}[hidealllines=true,backgroundcolor=gray!20]
\begin{description}
  \item[\R{}  data file:] \code{rent99} in package \pkg{gamlss.data} of dimensions $ 3081 \times 9$
   \item[{\bf var}]
   \begin{description}
      \item[\texttt{rent}]: the response variable which is the monthly net rent per month (in Euro)
    \item[\texttt{rentsqm}]: the net rent per month per square meter (in Euro)  
    \item[\texttt{area}]: living area in square meters.
    \item[\texttt{yearc}]: the year of construction
    \item[\texttt{location}]: the quality of location as a factor indicating whether the location is average, 1, good, 2, and top location, 3. 
   \item[\texttt{bath}]: the quality of bathroom: as a  factor indicating whether the bath facilities are standard, 0, or premium, 1
   \item[\texttt{kitchen}]: the quality of the kitchen: 0 standard, 1 premium
    \item[\texttt{cheating}]: central heating as a factor with two levels, 0, without central heating, 1 with central heating
   \item[\texttt{district}]: the district in Munich.
%above average (161 obs.) or not (1808 obs.)

  \end{description}
  \item[purpose:] to demonstrate fitting IAR models using \code{gamlss.spatial} {\bf R} package
\end{description}
\label{TheRentData}
\end{mdframed}   
We input the data and create a few new variables to take into account suitable interactions later. %\textcolor{red}{Mikis: I am not sure yet where we should create those interactions, Shall we wait for later? }

<<warning=FALSE, message=FALSE>>=
library(gamlss.spatial)
data(rent99)
data(rent99.polys)
rent99$cheating<-relevel(rent99$cheating,"1")
# creating new variables for interactions
# heating and years interaction
cy<-(as.numeric(rent99$cheating)-1)*rent99$yearc
# kitchen and years interation
ky<-(as.numeric(rent99$kitchen)-1)*rent99$yearc
# kitchen and area interation
ka<-(as.numeric(rent99$kitchen)-1)*rent99$area
# heating has its relevant level changed from 0 to 1 
heating<-relevel(rent99$cheating,"1")
rent99 <- transform(rent99,heating=heating, cy=cy, ky=ky, ka=ka) 
@

Figure \ref{fig:Rent99_data_resp} shows a histogram and a box-plot of the response variable \code{rent} which shows asymmetry and positive skewness. 
\rfigure{fig:Rent99_data_resp}
\label{r:Rent99_data_resp}
<<Rent99_data_resp, fig.show='hide', fig.asp=1>>=
hist(rent99$rent,ylab="f(y)",main="Histogram of rent", xlab="rent")
boxplot(rent99$rent)
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{Rent99_data_resp-1}
\includegraphics[width=.49\textwidth]{Rent99_data_resp-2}
\rpage{r:Rent99_data_resp}
\caption{A marginal histogram and box plot for  response variable \texttt{rent}.}
\label{fig:Rent99_data_resp}
\end{figure}

The complexity of the relationship between the response and the explanatory variables is shown in Figure \ref{fig:Rent99_data_xvar}. Note that those plots are  bivariate exploratory plots and take no account of the interactions between the explanatory variables. 
\rfigure{fig:Rent99_data_xvar}
\label{r:Rent99_data_xvar}
<<Rent99_data_xvar, fig.show='hide', fig.asp=1>>=
plot(rent99$rent~rent99$area, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="area", ylab="rent")
plot(rent99$rent~rent99$yearc, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="yearc", ylab="rent")
plot(rent99$rent~rent99$location, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="location", ylab="rent")
plot(rent99$rent~rent99$bath, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="bath", ylab="rent")
plot(rent99$rent~rent99$kitchen, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="kitchen", ylab="rent")
plot(rent99$rent~rent99$cheating, data=rent, col=gray(0.7), 
     pch = 15, cex = 0.5, xlab="cheating", ylab="rent")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-1}
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-2}\\
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-3}
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-4}\\
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-5}
\includegraphics[width=.49\textwidth]{Rent99_data_xvar-6}
\rpage{r:Rent99_data_xvar}
\caption{A response \texttt{rent} against the explanatory variables.}
\label{fig:Rent99_data_xvar}
\end{figure}

Here we use the strategy described in \cite{DBetal2016} where appropriate models for $\mu$, $\sigma$ and $\nu$  are selected first without taking into account the spatial structure of the data. We first fit a basic model \code{m0} and then we use the \code{stepGAICALL.A()} function to select  models for all the distribution parameters $\mu, \sigma$ and $\nu$. The selection takes several minutes and the output (which is omitted below) gives the steps to selecting the final model \code{m1}.
<<eval=FALSE>>=
m0<-gamlss(rent~location+bath+kitchen+cheating+area+yearc+pb(area)+pb(yearc),
           sigma.fo=~area + yearc + pb(area) + pb(yearc),
           nu.fo=~area + yearc + pb(area) + pb(yearc), family=BCCGo, 
           data=rent99)
m1 <- stepGAICAll.A(m0, scope=list(lower=~location+bath+kitchen+cheating+area+
        yearc+pb(area)+pb(yearc), upper=~(location+bath+kitchen+cheating+
        area+yearc)^2+pb(area)+pb(yearc)), sigma.scope=list(lower=~area+yearc,
        upper=~location+bath+kitchen+cheating+area+yearc+pb(area)+pb(yearc)),
        nu.scope=list(lower=~area+yearc, upper=~location+bath+kitchen+
        cheating+area+yearc+pb(area)+pb(yearc)),k=4)
@

% <<echo=FALSE, eval=TRUE, results='hide'>>=
% load("modelm0m1.Rdata")
% # load("/Users/MikisStasinopoulos/Dropbox/gamlss/R-code/Spatial/modelm0m1.Rdata")
% #save(m0, m1, file="/Users/MikisStasinopoulos/Dropbox/gamlss/R-code/Spatial/modelm0m1.Rdata")
% @
% The resulting chosen model is  presented here:
% <<warning=FALSE>>=
% summary(m1)
% @

Preparing to fit the IAR model for $\mu$ [using the interaction variables \code{cy}, \code{ky} and \code{ka}, so that the linear and smoothing (\code{pb}) effects for each continuous variable are combined together in the term plot for $\mu$].
<<>>=
fd<-as.factor(rent99$district)
farea<-as.factor(names(rent99.polys))
vizinhos <- polys2nb(rent99.polys)
#creating the precision matrix
precision <- nb2prec(vizinhos,fd,area=farea)
#adding spatial effect for mu
@
Fitting the reparametrized model \code{m1} with the additional IAR spatial model for $\mu$
<<eval=FALSE>>=
m2<- gamlss(formula = rent ~ location + bath + kitchen + cheating + 
            pb(area) + pb(yearc) + cy + ky + ka +
            gmrf(fd, area = farea, precision = precision, method="A"), 
            sigma.formula = ~area +  pb(yearc) + cheating, 
            nu.formula = ~pb(area) + pb(yearc) +  
            kitchen, family = BCCGo, data = rent99, start.from=m1)
@


<<eval=TRUE, echo=FALSE, results='hide'>>=
#load("/Users/MikisStasinopoulos/Dropbox/gamlss/R-code/Spatial/modelm2.Rdata")
load("mrf-rent-data-analysis-final2.Rdata")
#save(m2, file="/Users/MikisStasinopoulos/Dropbox/gamlss/R-code/Spatial/modelm2.Rdata")
@
Using AIC:
<<>>=
AIC(m1,m2, k=2)
@
Refitting the final  model with mean centred variables (\code{nyearc} and \code{narea}) in the interactions, so that the term plots for the factors are easier to interpret.
<<eval=FALSE>>=
rent99$nyearc<-rent99$yearc-mean(rent99$yearc)
rent99$narea<-rent99$area-mean(rent99$area)
m2final<- gamlss(formula = rent ~ location + bath + 
          cheating*nyearc + kitchen*nyearc +  
          kitchen*narea + pb(area) + pb(yearc) +
          gmrf(fd, area = farea, precision = precision), 
          sigma.formula = ~area  + cheating + pb(yearc), 
          nu.formula = ~  kitchen + pb(area) + pb(yearc), 
          family = BCCGo, data = rent99, start.from=m2) 
@


% # <<eval=TRUE, echo=FALSE, results='hide'>>=
% # load("modelm2final.Rdata")
% # #save(m2, file="/Users/MikisStasinopoulos/Dropbox/gamlss/R-code/Spatial/modelm2.Rdata")
% # @

Note that Figure \ref{fig:termplotmu} combines the term plots for $\mu$ for the explanatory factors obtained from \code{m2final}, with the term plots for $\mu$ for the explanatory continuous variables obtained from \code{m2}.

To plot the term plots for $\mu$. (Interactions are automatically omitted from the plots and also no spatial effect is plotted with this function).
\rfigure{fig:termplotmu}
\label{r:termplotmu}
<<termplotmu, fig.show='hide', fig.asp=1, warning=FALSE>>=
#to get the termplot for the factors (without interaction)
term.plot(m2final, what="mu", ylim="free")
@

<<termplotmu2, fig.show='hide', fig.asp=1, warning=FALSE>>=
#to get the termplot for the continuous variables 
term.plot(m2, what="mu", ylim="free")
@
[Note that the term plots for $\mu$ gives the contribution from the explanatory variables to the predictor of $\mu$, i.e. $\log \mu$, for the $BCCGo$ distribution.]
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{termplotmu-1}
\includegraphics[width=.49\textwidth]{termplotmu-2}\\
\includegraphics[width=.49\textwidth]{termplotmu-5}
\includegraphics[width=.49\textwidth]{termplotmu-3}\\
\includegraphics[width=.49\textwidth]{termplotmu2-5}
\includegraphics[width=.49\textwidth]{termplotmu2-6}
\rpage{r:termplotmu}
\caption{Term plots for $\mu$.}
\label{fig:termplotmu}
\end{figure}

To plot the term plot for the interactions we used an extra function called \texttt{int.term}, available at the website \url{www.gamlss.org}.
\rfigure{fig:termplotmuinteractions}
\label{r:termplotmuinteractions}
<<termplotmuinteractions, fig.show='hide', fig.asp=1, warning=FALSE>>=
source("int-term-plot.R")
#to find out the position of the interaction terms
head(lpred(m2final, type="terms")) 
int.term(object=m2final, xvar=rent99$yearc, position=10, 
         fac=rent99$cheating, factor.plots=TRUE, xlabel="yearc", 
         ylabel="cheating", which.lev="0")
int.term(object=m2final, xvar=rent99$yearc, position=11, 
         fac=rent99$kitchen, factor.plots=TRUE, 
         xlabel="yearc", ylabel="kitchen", which.lev="1")
int.term(object=m2final, xvar=rent99$area, position=12, 
         fac=rent99$kitchen, factor.plots=TRUE, 
         xlabel="area", ylabel="kitchen", which.lev="1")
@

\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{termplotmuinteractions-1}
\includegraphics[width=.49\textwidth]{termplotmuinteractions-2}\\
\includegraphics[width=.49\textwidth]{termplotmuinteractions-3}
\rpage{r:termplotmuinteractions}
\caption{Term plots of the interactions for $\mu$.}
\label{fig:termplotmuinteractions}
\end{figure}

To plot the term plot for the spatial effect for $\mu$.
\rfigure{fig:fittedspatial}
\label{r:fittedspatial}
<<fittedspatial, fig.show='hide', fig.asp=1>>=
draw.polys(rent99.polys,getSmo(m2final, what="mu", which=3), 
           scheme="heat")
@
[Note that \texttt{which=3} is used in order to choose the third smoothing term for $\mu$, which corresponds to the spatial term in the \texttt{m2final} model.]
\begin{figure}[!htbp]
\centering
\includegraphics[width=.69\textwidth]{fittedspatial-1}
\rpage{r:fittedspatial}
\caption{The fitted spatial effect for $\mu$ for the chosen model with spatial effect.}
\label{fig:fittedspatial}
\end{figure}

To plot the term plots for $\sigma$ and $\nu$ (which give the contributions from the explanatory variables to the predictor of $\sigma$ and $\nu$, i.e. $\log \sigma$ and $\nu$, respectively).

\rfigure{fig:termplotsigma}
\label{r:termplotsigma}
<<termplotsigma, fig.show='hide', fig.asp=1>>=
term.plot(m2final, what="sigma", ylim="free")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{termplotsigma-2}
\includegraphics[width=.49\textwidth]{termplotsigma-1}\\
\includegraphics[width=.49\textwidth]{termplotsigma-3}
\rpage{r:termplotsigma}
\caption{Term plots for $\sigma$.}
\label{fig:termplotsigma}
\end{figure}

\rfigure{fig:termplotnu}
\label{r:termplotnu}
<<termplotnu, fig.show='hide', fig.asp=1>>=
term.plot(m2final, what="nu", ylim="free")
@
\begin{figure}[!htbp]
\centering
\includegraphics[width=.49\textwidth]{termplotnu-1}
\includegraphics[width=.49\textwidth]{termplotnu-3}\\
\includegraphics[width=.49\textwidth]{termplotnu-2}
\rpage{r:termplotnu}
\caption{Term plots for $\nu$.}
\label{fig:termplotnu}
\end{figure}

The fitted model is given by:
<<>>=
summary(m2final)
@

The residual diagnostics plot, the worm plot, for the final model.
\rfigure{fig:plotwp}
\label{r:plotwp}
<<plotwp, fig.show='hide', fig.asp=1, warning=FALSE, message=FALSE>>=
wp(m2final, ylim.all=0.7)
@

\begin{figure}[!htbp]
\centering
\includegraphics[width=.69\textwidth]{plotwp-1}
\rpage{r:plotwp}
\caption{Worm plot of the residuals for the chosen final model {\tt m2final}.}
\label{fig:plotwp}
\end{figure}

Worm plots for cases in each of the 16 joint intervals for different combinations of the two continuous explanatory variables {\tt yearc} and {\tt area}.

\rfigure{fig:plotvwp}
\label{r:plotvwp}
<<plotvwp, fig.show='hide', fig.asp=1, warning=FALSE, message=FALSE>>=
wp(m2final, xvar=~yearc+area, n.inter=4, ylim.worm=1)
@
%wp(m2final, xvar=~yearc+kitchen, n.inter=4, ylim.worm=.8)

\begin{figure}[!htbp]
\centering
\includegraphics[width=.69\textwidth]{plotvwp-1}
%\includegraphics[width=.69\textwidth]{plotvwp-2}
\rpage{r:plotvwp}
\caption{Worm plot of the residuals split by the {\tt yearc} and {\tt area} variables for the final model.}
\label{fig:plotvwp}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Conclusions}
\label{Conclusions}

We  have shown that the GAMLSS framework provides a platform to fit, compare  and check spatial models for the parameters of the distribution of a response variable which may be non exponential family. For more details about GMRF (and in particular IAR models) in GAMLSS see \cite{DBetal2016}.

\printindex

\bibliographystyle{plainnat}  
\bibliography{Book-2016}

\end{document}
